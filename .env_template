# ---------- API KEYS ---------- #
OPENAI_API_KEY = ""
OPENROUTER_API_KEY=""
GEMINI_API_KEY=""

# ---------- MILVUS ---------- #
MILVUS_URL="http://localhost:19530"
MILVUS_DATABASE_NAME="fAIth"
MILVUS_USERNAME="root"
MILVUS_PASSWORD="Milvus"

# ---------- EMBEDDING MODEL ---------- #
EMBEDDING_MODEL_RUNNER = "hf_sentence_transformers"
# EMBEDDING_MODEL_RUNNER = "llama_cpp"
# EMBEDDING_MODEL_RUNNER = "ollama"
# EMBEDDING_MODEL_RUNNER = "docker_model_runner"

EMBEDDING_MODEL_ID = "Qwen/Qwen3-Embedding-0.6B"

# Llama CPP Python and HF Transformers
# DEVICE="cpu"
EMBEDDING_DEVICE="cuda"

# Llama CPP Python specific things
EMBEDDING_MODEL_REPO = ""
# The GPU_LAYERS variable is used in the Llama CPP Python runner to specify the number of layers to offload to the GPU
# This is only used if the DEVICE is set to "cuda", otherwise the number of GPU_LAYERS is automatically 0
EMBEDDING_GPU_LAYERS=32

# ---------- RERANKING MODEL ---------- #
RERANKING_RUNNER = "hf_transformers"
RERANKING_MODEL_ID= "Qwen/Qwen3-Reranker-0.6B"

